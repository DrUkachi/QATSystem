{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the Test Notebook to test the API\n",
    "\n",
    "Before you use the notebook please ensure you have\n",
    "\n",
    "1. Followed the instructions on the README\n",
    "2. The Postgres Database is up and running - if you restarted your laptop, device or environment you can use this\n",
    "```bash\n",
    "sudo service postgresql start\n",
    "```\n",
    "If you are using Windows, just start the Postgres Software\n",
    "\n",
    "To confirm that it works you can use this\n",
    "\n",
    "```bash\n",
    "psql -U your_username -d your_database_name\n",
    "```\n",
    "You the put your password and ensure its at least connected\n",
    "\n",
    "\n",
    "3. The flask app has been started. You can use the following command to get started\n",
    "\n",
    "```bash\n",
    "python flask_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Set the base URL for the Flask API\n",
    "BASE_URL = \"http://localhost:8080\"  # Adjust as necessary\n",
    "\n",
    "def test_upload_file(file_path):\n",
    "    \"\"\"Test the file upload endpoint.\"\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        response = requests.post(f\"{BASE_URL}/upload\", files={\"file\": file})\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Upload successful:\", response.json())\n",
    "    else:\n",
    "        print(\"Upload failed:\", response.status_code, response.json())\n",
    "    \n",
    "    return response\n",
    "\n",
    "def test_process_query(query):\n",
    "    \"\"\"Test the process query endpoint.\"\"\"\n",
    "    payload = {\"query\": query}\n",
    "    response = requests.post(f\"{BASE_URL}/query\", json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Query processing successful:\", response.json())\n",
    "    else:\n",
    "        print(\"Query processing failed:\", response.status_code, response.json())\n",
    "    \n",
    "    return response\n",
    "\n",
    "def test_evaluate_user_answer(test_question_id, user_answer):\n",
    "    \"\"\"Test the evaluate user answer endpoint.\"\"\"\n",
    "    payload = {\n",
    "        \"answer\": user_answer,\n",
    "        \"test_question_id\": test_question_id\n",
    "    }\n",
    "    response = requests.post(f\"{BASE_URL}/evaluate\", json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Evaluation successful:\", response.json())\n",
    "    else:\n",
    "        print(\"Evaluation failed:\", response.status_code, response.json())\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_path = \"/teamspace/studios/this_studio/QATSystem/sample_file/2005.11401v4.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload failed: 202 {'message': 'File uploaded successfully. Knowledge base creation started.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [202]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_upload_file(sample_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query processing successful: {'answer': 'Based on the information provided in the documents, one potential disadvantage of RAG is that it may require many forward passes for longer output sequences during the decoding process, which can be less efficient. Additionally, retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, meaning that while the model may match more words from the reference answer, it may not generate the exact correct answer as frequently.\\n\\nAnother potential downside of RAG is that, like any language model that relies on external knowledge sources, it is only as factual and unbiased as the knowledge source it is trained on, in this case, Wikipedia. This means that there is a risk of generating factually incorrect or biased information.\\n\\nAdditionally, RAG could potentially be used to generate abuse, fake or misleading content, similar to concerns with other language models such as GPT-2. However, the document suggests that these concerns may be valid but to a lesser extent for RAG.', 'bullet_points': [\"Bullet Point 1: RAG's decoding process, specifically for RAG-Sequence, may require many forward passes for longer output sequences, which can lead to reduced efficiency and increased computational requirements. This is because the likelihood of an output sequence is calculated by running a beam search for each document, scoring each hypothesis, and then estimating the probability of a hypothesis by running additional forward passes for documents where the hypothesis did not appear in the beam.\", 'Bullet Point 2: Retrieving more documents can lead to higher Rouge-L scores for RAG-Token, indicating that the model matches more words from the reference answer. However, this comes at the expense of Bleu-1 scores, which means that the exact correct answer is not generated as frequently. This trade-off between Rouge-L and Bleu-1 scores suggests that while RAG can generate responses that are more similar to the reference answer, it may not always generate the exact correct answer.', 'Bullet Point 3: Like any language model that relies on external knowledge sources, RAG is only as factual and unbiased as the knowledge source it is trained on. Therefore, there is a risk of generating factually incorrect or biased information. Additionally, RAG could potentially be used to generate abuse, fake or misleading content, similar to concerns with other language models such as GPT-2. However, the document suggests that these concerns may be valid but to a lesser extent for RAG.'], 'test_question': 'How might the efficiency of RAG be impacted during the decoding process, and what trade-off could arise when retrieving more documents in RAG-Token?', 'test_question_id': 'f023688b-6536-468f-b608-7bfe68a3cb95'}\n"
     ]
    }
   ],
   "source": [
    "response = test_process_query(\"What are the disadvantages of RAG?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Based on the information provided in the documents, one potential disadvantage of RAG is that it may require many forward passes for longer output sequences during the decoding process, which can be less efficient. Additionally, retrieving more documents leads to higher Rouge-L for RAG-Token at the expense of Bleu-1, meaning that while the model may match more words from the reference answer, it may not generate the exact correct answer as frequently.\\n\\nAnother potential downside of RAG is that, like any language model that relies on external knowledge sources, it is only as factual and unbiased as the knowledge source it is trained on, in this case, Wikipedia. This means that there is a risk of generating factually incorrect or biased information.\\n\\nAdditionally, RAG could potentially be used to generate abuse, fake or misleading content, similar to concerns with other language models such as GPT-2. However, the document suggests that these concerns may be valid but to a lesser extent for RAG.',\n",
       " 'bullet_points': [\"Bullet Point 1: RAG's decoding process, specifically for RAG-Sequence, may require many forward passes for longer output sequences, which can lead to reduced efficiency and increased computational requirements. This is because the likelihood of an output sequence is calculated by running a beam search for each document, scoring each hypothesis, and then estimating the probability of a hypothesis by running additional forward passes for documents where the hypothesis did not appear in the beam.\",\n",
       "  'Bullet Point 2: Retrieving more documents can lead to higher Rouge-L scores for RAG-Token, indicating that the model matches more words from the reference answer. However, this comes at the expense of Bleu-1 scores, which means that the exact correct answer is not generated as frequently. This trade-off between Rouge-L and Bleu-1 scores suggests that while RAG can generate responses that are more similar to the reference answer, it may not always generate the exact correct answer.',\n",
       "  'Bullet Point 3: Like any language model that relies on external knowledge sources, RAG is only as factual and unbiased as the knowledge source it is trained on. Therefore, there is a risk of generating factually incorrect or biased information. Additionally, RAG could potentially be used to generate abuse, fake or misleading content, similar to concerns with other language models such as GPT-2. However, the document suggests that these concerns may be valid but to a lesser extent for RAG.'],\n",
       " 'test_question': 'How might the efficiency of RAG be impacted during the decoding process, and what trade-off could arise when retrieving more documents in RAG-Token?',\n",
       " 'test_question_id': 'f023688b-6536-468f-b608-7bfe68a3cb95'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Bullet Point 1: RAG's decoding process, specifically for RAG-Sequence, may require many forward passes for longer output sequences, which can lead to reduced efficiency and increased computational requirements. This is because the likelihood of an output sequence is calculated by running a beam search for each document, scoring each hypothesis, and then estimating the probability of a hypothesis by running additional forward passes for documents where the hypothesis did not appear in the beam.\",\n",
       " 'Bullet Point 2: Retrieving more documents can lead to higher Rouge-L scores for RAG-Token, indicating that the model matches more words from the reference answer. However, this comes at the expense of Bleu-1 scores, which means that the exact correct answer is not generated as frequently. This trade-off between Rouge-L and Bleu-1 scores suggests that while RAG can generate responses that are more similar to the reference answer, it may not always generate the exact correct answer.',\n",
       " 'Bullet Point 3: Like any language model that relies on external knowledge sources, RAG is only as factual and unbiased as the knowledge source it is trained on. Therefore, there is a risk of generating factually incorrect or biased information. Additionally, RAG could potentially be used to generate abuse, fake or misleading content, similar to concerns with other language models such as GPT-2. However, the document suggests that these concerns may be valid but to a lesser extent for RAG.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['bullet_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the information provided in the documents, one potential '\n",
      " 'disadvantage of RAG is that it may require many forward passes for longer '\n",
      " 'output sequences during the decoding process, which can be less efficient. '\n",
      " 'Additionally, retrieving more documents leads to higher Rouge-L for '\n",
      " 'RAG-Token at the expense of Bleu-1, meaning that while the model may match '\n",
      " 'more words from the reference answer, it may not generate the exact correct '\n",
      " 'answer as frequently.\\n'\n",
      " '\\n'\n",
      " 'Another potential downside of RAG is that, like any language model that '\n",
      " 'relies on external knowledge sources, it is only as factual and unbiased as '\n",
      " 'the knowledge source it is trained on, in this case, Wikipedia. This means '\n",
      " 'that there is a risk of generating factually incorrect or biased '\n",
      " 'information.\\n'\n",
      " '\\n'\n",
      " 'Additionally, RAG could potentially be used to generate abuse, fake or '\n",
      " 'misleading content, similar to concerns with other language models such as '\n",
      " 'GPT-2. However, the document suggests that these concerns may be valid but '\n",
      " 'to a lesser extent for RAG.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.json()['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How might the efficiency of RAG be impacted during the decoding process, and what trade-off could arise when retrieving more documents in RAG-Token?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['test_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question_id = response.json()['test_question_id']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see that the evaluation works you can use two examples\n",
    "\n",
    "A wrong answer and a correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_generated_answer = \"\"\"I don't know the answer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation successful: {'knowledge_confidence': 5, 'knowledge_understood': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluate_user_answer(test_question_id,\n",
    "wrong_generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_generated_answer = \"\"\"The quality of retrieved documents significantly impacts the performance of RAG (Retrieval Augmented Generation) models. If the retrieved documents are irrelevant, inaccurate, or incomplete, the model will likely generate incorrect or misleading responses. Therefore, it's crucial to ensure the quality of the document corpus used for RAG.\n",
    "\n",
    "Here are some potential solutions to mitigate the dependence on document quality:\n",
    "\n",
    "Document Filtering and Curation: Implement mechanisms to filter and curate the document corpus, removing irrelevant or low-quality documents. This can involve using keyword matching, topic modeling, or other techniques to identify relevant documents.\n",
    "\n",
    "Document Ranking: Rank retrieved documents based on their relevance to the query. This can be achieved using techniques like cosine similarity, TF-IDF, or more advanced ranking algorithms. By prioritizing relevant documents, the model can generate more accurate responses.\n",
    "\n",
    "Multiple Document Retrieval: Retrieve multiple documents related to the query and combine their information to generate a more comprehensive response. This can help mitigate the impact of individual document quality issues.\n",
    "\n",
    "Contextual Awareness: Enhance the model's ability to understand the context of the query and the retrieved documents. This can involve using techniques like semantic analysis or knowledge graphs to identify relationships between concepts and information.\n",
    "\n",
    "Feedback Mechanisms: Incorporate feedback mechanisms to allow users to provide feedback on the generated responses. This feedback can be used to improve the model's performance over time by identifying and addressing issues related to document quality and response accuracy.\n",
    "\n",
    "By addressing these factors, RAG models can become more robust and less reliant on the quality of individual documents, leading to improved performance and more accurate responses..\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation successful: {'knowledge_confidence': 68, 'knowledge_understood': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluate_user_answer(test_question_id,\n",
    "correct_generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation successful: {'knowledge_confidence': 11, 'knowledge_understood': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluate_user_answer(test_question_id,\n",
    "wrong_generated_answer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
